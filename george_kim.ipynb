{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "# from statistics import *\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "corpuscsv = open(os.path.join(cwd, 'corpus_1vote_textEncoding_filter.csv'))\n",
    "reader = csv.reader(corpuscsv)\n",
    "corpusList = list(reader)\n",
    "corpuscsv.close()\n",
    "\n",
    "numwordf = open(os.path.join(cwd,'numwordsList.csv'))\n",
    "readernumword = csv.reader(numwordf)\n",
    "numwordsList = list(readernumword)\n",
    "intnumwordsList = list(map((lambda s: int(s[0])),numwordsList))\n",
    "numwordf.close()\n",
    "\n",
    "ratingsf = open(os.path.join(cwd,'ratings.csv'))\n",
    "readerratings = csv.reader(ratingsf)\n",
    "ratingsList = list(readerratings)\n",
    "intstarlist = list(map((lambda s: int(s[0])), ratingsList))\n",
    "ratingsf.close()\n",
    "\n",
    "print('number of instances (reviews): ' + str(len(corpusList))+'\\n')\n",
    "print('the instances are text data, and the features are unigram, bigrams and trigrams.\\n')\n",
    "print('Only the top 100 are printed.\\n')\n",
    "\n",
    "######################################################################\n",
    "# split massive corpus into tiny pieces\n",
    "###################################################################\n",
    "lines_per_file = 15000\n",
    "smallfile = None\n",
    "with open(os.path.join(cwd, 'corpus_1vote_textEncoding_filter.txt'),'r') as bigfile:\n",
    "    for lineno, line in enumerate(bigfile):\n",
    "        if lineno % lines_per_file == 0:\n",
    "            if smallfile:\n",
    "                smallfile.close()\n",
    "            small_filename = os.path.join(cwd,'small_file_{}.txt').format(lineno + lines_per_file)\n",
    "            smallfile = open(small_filename, 'w')\n",
    "        smallfile.write(line)\n",
    "    if smallfile:\n",
    "        smallfile.close()\n",
    "\n",
    "###################################################################################\n",
    "# Use count vectorizer on each piece\n",
    "###################################################################################\n",
    "smallfile_list = glob.glob(os.path.join(cwd,'small_file_*.txt'))\n",
    "count = 0\n",
    "for smallfile in smallfile_list:\n",
    "    f = open(smallfile)\n",
    "    cv = CountVectorizer(ngram_range=(1, 3), stop_words='english', max_features=300,strip_accents='unicode',\n",
    "                         decode_error='ignore')\n",
    "\n",
    "    X = cv.fit_transform(f)\n",
    "    matrix_terms = np.array(cv.get_feature_names())\n",
    "\n",
    "    # Use the axis keyword to sum over rows\n",
    "    matrix_freq = np.asarray(X.sum(axis=0)).ravel()\n",
    "    final_matrix = np.array([matrix_terms,matrix_freq])\n",
    "    final_matrixlist = final_matrix.tolist()\n",
    "    f.close()\n",
    "    with open(os.path.join(cwd,'small_file_'+str(count)+'.csv'), 'w') as outfile:\n",
    "        for data_slice in final_matrixlist:\n",
    "            for item in data_slice:\n",
    "                outfile.write(item+',')\n",
    "            # Writing out a break to indicate different slices...\n",
    "            outfile.write('\\n')\n",
    "    count+=1\n",
    "    outfile.close()\n",
    "\n",
    "###############################################################################\n",
    "# combine the frequencies of the n-grams across the corpus pieces\n",
    "#################################################################################\n",
    "smallfile_list = glob.glob(os.path.join(cwd,'small_file_*.csv'))\n",
    "count = 0\n",
    "featurefrequencydict = {}\n",
    "for smallfile in smallfile_list:\n",
    "    f = open(smallfile)\n",
    "    reader = csv.reader(f)\n",
    "    list_list = list(reader)\n",
    "    featurelista = list_list[0]\n",
    "    frequencylista = list_list[1]\n",
    "    # try:\n",
    "    #     d = []\n",
    "    #     featurefrequencydicta = {d[0]:int(d[1]) for d in zip(featurelista,frequencylista)}\n",
    "    # except:\n",
    "    featurefrequencydicta = {}\n",
    "    for d in zip(featurelista,frequencylista):\n",
    "        if (d[0] != '' and  d[1] != ''):\n",
    "            featurefrequencydicta[d[0]] = int(d[1])\n",
    "    for d in featurefrequencydicta.items():\n",
    "        if d[0] not in featurefrequencydict.keys():\n",
    "            featurefrequencydict[d[0]]=0\n",
    "        featurefrequencydict[d[0]]=featurefrequencydict[d[0]]+d[1]\n",
    "    f.close()\n",
    "\n",
    "outfile = open(os.path.join(cwd,'featurefrequency.csv'),'w')\n",
    "\n",
    "list_key_value = [[d[0],d[1]] for d in featurefrequencydict.items()]\n",
    "list_key_value.sort(key=lambda x: x[1],reverse=True)\n",
    "for i in range(0,100):\n",
    "    if i < 99:\n",
    "        outfile.write(list_key_value[i][0]+',')\n",
    "    if i == 99:\n",
    "        outfile.write(list_key_value[i][0]+'\\n')\n",
    "for i in range(0,100):\n",
    "    if i < 99:\n",
    "        outfile.write(str(list_key_value[i][1])+',')\n",
    "    if i == 99:\n",
    "        outfile.write(str(list_key_value[i][1]))\n",
    "outfile.close()\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# print feature frequencies\n",
    "##################################################################\n",
    "with open(os.path.join(cwd,'featurefrequency.csv'), 'r') as ff:\n",
    "    readerff = csv.reader(ff)\n",
    "    ff_list = list(readerff)\n",
    "ff.close()\n",
    "ffzip = zip(ff_list[0],ff_list[1])\n",
    "for item in ffzip:\n",
    "    print(item[0]+\": \"+item[1])\n",
    "\n",
    "###############################################################################\n",
    "# I wanted to see the histogram of the length of reviews for extra visualization.\n",
    "#\n",
    "# plot histogram of length of reviews (length as in number of whitespace delimited alpha-numeric characters)\n",
    "###############################################################################\n",
    "hist, bins = np.histogram(intnumwordsList, bins=13)\n",
    "width = 0.8 * (bins[1] - bins[0])\n",
    "# width = 28\n",
    "# bins = [1, 41, 81, ... 1041]\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "# center = [21, 61, 101, ..., 1021]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.bar(center, hist, align='center', width=width)\n",
    "ax1.set_title('Word Length Histogram of Reviews')\n",
    "wordnum = range(1,1441, 80)\n",
    "ax1.set_xticks(bins)\n",
    "ax1.set_xticklabels(labels=wordnum, rotation=45, rotation_mode=\"anchor\", ha=\"right\")\n",
    "plt.savefig(os.path.join(cwd, 'LengthReview_Histogram'))\n",
    "plt.close()\n",
    "\n",
    "##############################################################################\n",
    "# print statistics\n",
    "##############################################################################\n",
    "starmean = sum(intstarlist)/len(intstarlist)\n",
    "starvariance = np.var(intstarlist)\n",
    "print(\"Ratings Mean: {:.2f}, Variance: {:.2f}\".format(starmean, starvariance))\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# plot histogram of ratings\n",
    "##############################################################################\n",
    "hist, bins = np.histogram(intstarlist, bins=8)\n",
    "width = 0.8 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "ax.set_title('Histogram of Ratings')\n",
    "numbers = range(2,11)\n",
    "numbers2 = []\n",
    "for n in numbers:\n",
    "    numbers2.append(n/2)\n",
    "ax.set_xticks(numbers2)\n",
    "ax.set_xticklabels(['1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '5'], rotation=45, rotation_mode=\"anchor\",\n",
    "                   ha=\"right\")\n",
    "plt.savefig(os.path.join(cwd, 'Ratings_Histogram'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#####################################################################################\n",
    "#plot boxplot of ratings\n",
    "#####################################################################################\n",
    "fig2, ax2 = plt.subplots()\n",
    "plt.boxplot(intstarlist, notch=True, patch_artist=True)\n",
    "ax2.set_title('BoxPlot of Ratings')\n",
    "plt.savefig(os.path.join(cwd, 'Ratings_BoxPlot'))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}